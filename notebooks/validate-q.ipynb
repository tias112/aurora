{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client import ElasticClient\n",
    "client = ElasticClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "env: DATABASE_URL=\"postgresql://user:password@localhost/interstorage?connect_timeout=10&application_name=myapp\"\n",
      "init KIndexCalculator\n",
      "invalid dsn: invalid connection option \"\"postgresql://user:password@localhost/interstorage?connect_timeout\"\n",
      "\n",
      "preliminary_k_index_last_24_01-08_1745.png\n",
      "{\n",
      "  \"query\": {\n",
      "    \"range\": {\n",
      "      \"@timestamp\": {\n",
      "        \"gte\": \"2022-01-08T17:45:00.000Z\",\n",
      "        \"lte\": \"2022-01-09T17:45:00.000Z\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"runtime_mappings\": {\n",
      "    \"f.calc\": {\n",
      "      \"type\": \"double\",\n",
      "      \"script\": \"emit(doc['xComp'].value+doc['yComp'].value/5)\"\n",
      "    }\n",
      "  },\n",
      "  \"size\": 0,\n",
      "  \"aggs\": {\n",
      "    \"avg_x\": {\n",
      "      \"avg\": {\n",
      "        \"field\": \"xComp\"\n",
      "      }\n",
      "    },\n",
      "    \"avg_y\": {\n",
      "      \"avg\": {\n",
      "        \"field\": \"yComp\"\n",
      "      }\n",
      "    },\n",
      "    \"avg_z\": {\n",
      "      \"avg\": {\n",
      "        \"field\": \"zComp\"\n",
      "      }\n",
      "    },\n",
      "    \"calc\": {\n",
      "      \"date_histogram\": {\n",
      "        \"field\": \"@timestamp\",\n",
      "        \"fixed_interval\": \"15m\"\n",
      "      },\n",
      "      \"aggs\": {\n",
      "        \"max_x\": {\n",
      "          \"max\": {\n",
      "            \"field\": \"xComp\"\n",
      "          }\n",
      "        },\n",
      "        \"min_x\": {\n",
      "          \"min\": {\n",
      "            \"field\": \"xComp\"\n",
      "          }\n",
      "        },\n",
      "        \"max_y\": {\n",
      "          \"max\": {\n",
      "            \"field\": \"yComp\"\n",
      "          }\n",
      "        },\n",
      "        \"min_y\": {\n",
      "          \"min\": {\n",
      "            \"field\": \"yComp\"\n",
      "          }\n",
      "        },\n",
      "        \"max_z\": {\n",
      "          \"max\": {\n",
      "            \"field\": \"zComp\"\n",
      "          }\n",
      "        },\n",
      "        \"min_z\": {\n",
      "          \"min\": {\n",
      "            \"field\": \"zComp\"\n",
      "          }\n",
      "        },\n",
      "        \"max_q\": {\n",
      "          \"max\": {\n",
      "            \"field\": \"q\"\n",
      "          }\n",
      "        },\n",
      "        \"x_delta\": {\n",
      "          \"bucket_script\": {\n",
      "            \"buckets_path\": {\n",
      "              \"max_x\": \"max_x\",\n",
      "              \"min_x\": \"min_x\"\n",
      "            },\n",
      "            \"script\": \"params.max_x - params.min_x\"\n",
      "          }\n",
      "        },\n",
      "        \"y_delta\": {\n",
      "          \"bucket_script\": {\n",
      "            \"buckets_path\": {\n",
      "              \"max_y\": \"max_y\",\n",
      "              \"min_y\": \"min_y\"\n",
      "            },\n",
      "            \"script\": \"params.max_y - params.min_y\"\n",
      "          }\n",
      "        },\n",
      "        \"z_delta\": {\n",
      "          \"bucket_script\": {\n",
      "            \"buckets_path\": {\n",
      "              \"max_z\": \"max_z\",\n",
      "              \"min_z\": \"min_z\"\n",
      "            },\n",
      "            \"script\": \"params.max_z - params.min_z\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "train_data:95 total mismatches: {0: 0.17525773195876287, 1: 0} from 0\n",
      "elastic size:97 need append: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from PIL import Image\n",
    "import logging\n",
    "from time import sleep\n",
    "import os\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from kiruna.k_calculator import KIndexCalculator\n",
    "from kiruna.k_calculator import get_probability\n",
    "from kiruna.k_calculator import get_K_index\n",
    "import numpy\n",
    "print('start')\n",
    "#%env DATABASE_URL=\"dbname=interstorage user=user password=password\"\n",
    "%env DATABASE_URL=\"postgresql://user:password@localhost/interstorage?connect_timeout=10&application_name=myapp\"\n",
    "calculator = KIndexCalculator()\n",
    "\n",
    "train_data=[]\n",
    "\n",
    "def generate_train_data(test_q, test_q_prev, kiruna_Q):\n",
    "    \n",
    "    if 'max_x' in test_q.keys():\n",
    "        xAmp_15=test_q['max_x'] - test_q['min_x']\n",
    "        yAmp_15=test_q['max_y'] - test_q['min_y']\n",
    "    elif 'max_x' in test_q_prev.keys():\n",
    "        xAmp_15=test_q_prev['max_x'] - test_q_prev['min_x']\n",
    "        yAmp_15=test_q_prev['max_y'] - test_q_prev['min_y']\n",
    "    else:\n",
    "        xAmp_15=0\n",
    "        yAmp_15=0\n",
    "    xQ_15 = get_K_index(xAmp_15)\n",
    "    yQ_15 = get_K_index(yAmp_15)\n",
    "\n",
    "    if 'max_x' in test_q_prev.keys() and 'max_x' in test_q.keys():\n",
    "        xAmp_30=max(test_q['max_x'], test_q_prev['max_x']) - min(test_q['min_x'], test_q_prev['min_x'])\n",
    "        yAmp_30=max(test_q['max_y'], test_q_prev['max_y']) - min(test_q['min_y'], test_q_prev['min_y'])\n",
    "        xQ_30 = get_K_index(xAmp_30)\n",
    "        yQ_30 = get_K_index(yAmp_30)\n",
    "        #print([test_q['max_x'], test_q_prev['max_x']])\n",
    "        #print([test_q['min_x'], test_q_prev['min_x']])\n",
    "        return [\"{:.2f}\".format(xAmp_30), \n",
    "                \"{:.2f}\".format(yAmp_30),\n",
    "                \"{:.2f}\".format(xAmp_15),\n",
    "                \"{:.2f}\".format(yAmp_15),\n",
    "                str(xQ_30),\n",
    "                str(xQ_15),\n",
    "                str(yQ_15),\n",
    "                str(kiruna_Q)]        \n",
    "    else:        \n",
    "        return [\"{:.2f}\".format(xAmp_15), \n",
    "                \"{:.2f}\".format(yAmp_15),\n",
    "                \"{:.2f}\".format(xAmp_15),\n",
    "                \"{:.2f}\".format(yAmp_15),\n",
    "                str(xQ_15),\n",
    "                str(xQ_15),\n",
    "                str(yQ_15),\n",
    "                str(kiruna_Q)]        \n",
    "\n",
    "\n",
    "    \n",
    "def analising(filename, elastic_q):\n",
    "    global train_data\n",
    "    #img = urllib.request.urlopen(\n",
    "         #   \"http://www2.irf.se/maggraphs/preliminary_k_index_last_24.png\", timeout=30).read()\n",
    "    #out = open(\"K&Q index.png\", \"wb\")\n",
    "    #out.write(img)\n",
    "    #out.close()\n",
    "\n",
    "    image = Image.open(filename)\n",
    "    pix = image.load()\n",
    "    start_x = 670\n",
    "    end_x = 1185\n",
    "    x = 1185\n",
    "    y_1 = 145\n",
    "    y_2 = 131\n",
    "    y_3 = 118\n",
    "    y_4 = 105\n",
    "    y_5 = 91\n",
    "    y_6 = 78\n",
    "    y_7 = 65\n",
    "    y_8 = 51\n",
    "    y_9 = 38\n",
    "    sample_color = str((255, 255, 255))\n",
    "    mismatches={0:0,1:0}\n",
    "    q=0\n",
    "    train_q = []\n",
    "    predict_q1 = []\n",
    "    for n in list(range(0,95)):\n",
    "        prev_q = q\n",
    "        x = 670 + int(n * (end_x-start_x) / 94)\n",
    "        \n",
    "        if str((pix[x-1, y_9]))  != sample_color or str((pix[x+1, y_9]))  != sample_color or str((pix[x, y_9])) != sample_color:\n",
    "            q = 9\n",
    "        elif str((pix[x-1, y_8]))  != sample_color or str((pix[x+1, y_8]))  != sample_color or str((pix[x, y_8])) != sample_color:\n",
    "            q = 8\n",
    "        elif str((pix[x-1, y_7]))  != sample_color or str((pix[x+1, y_7]))  != sample_color or str((pix[x, y_7])) != sample_color:\n",
    "            q = 7\n",
    "        elif str((pix[x-1, y_6]))  != sample_color or str((pix[x+1, y_6]))  != sample_color or str((pix[x, y_6])) != sample_color:\n",
    "            q = 6\n",
    "        elif str((pix[x-1, y_5]))  != sample_color or str((pix[x+1, y_5]))  != sample_color or str((pix[x, y_5])) != sample_color:\n",
    "            q = 5\n",
    "        elif str((pix[x-1, y_4]))  != sample_color or str((pix[x+1, y_4]))  != sample_color or str((pix[x, y_4])) != sample_color:\n",
    "            q = 4\n",
    "        elif str((pix[x-1, y_3]))  != sample_color or str((pix[x+1, y_3]))  != sample_color or str((pix[x, y_3])) != sample_color:\n",
    "            q = 3\n",
    "        elif str((pix[x-1, y_2]))  != sample_color or str((pix[x+1, y_2]))  != sample_color or str((pix[x, y_2])) != sample_color:\n",
    "            q = 2\n",
    "        elif str((pix[x-1, y_1]))  != sample_color or str((pix[x+1, y_1]))  != sample_color or str((pix[x, y_1])) != sample_color:\n",
    "            q = 1\n",
    "        else:\n",
    "            q = 0\n",
    "        if n<len(elastic_q):\n",
    "            if n>0:\n",
    "                test_q_value=calculator.calculate_q_4(elastic_q[n], elastic_q[n-1])\n",
    "                train_data.append(generate_train_data(elastic_q[n], elastic_q[n-1],q))\n",
    "            else:\n",
    "                test_q_value=calculator.calculate_q_4(elastic_q[n], elastic_q[n])\n",
    "                train_data.append(generate_train_data(elastic_q[n], elastic_q[n-1],q))\n",
    "            train_q.append(q)            \n",
    "            predict_q1.append(test_q_value)\n",
    "            if (test_q_value!=q and test_q_value!=prev_q):\n",
    "                mismatches[0]+=1/len(elastic_q)\n",
    "#            test_q_value=kindex_calc.calculate_q_3(predict_q[n], min(predict_q[0]['min_x'],predict_q[40]['min_x']),\n",
    " #                                      min(predict_q[0]['min_y'],predict_q[40]['min_y']))\n",
    "            \n",
    "     #       print(\"n: \"+ str(n)+ \"  q = \" + str(q) + \" test_q = \"+str(test_q_value))\n",
    "  #          if (test_q_value!=q and test_q_value!=prev_q):\n",
    "   #             mismatches[1]+=1/len(predict_q)\n",
    "\n",
    "    \n",
    "    print(\"train_data:\"+str(len(train_data))+\" total mismatches: \"+ str(mismatches) + \" from \" + str(len(predict_q)))\n",
    "    return train_q, predict_q1\n",
    "\n",
    "def get_image_data_range(filename, delta):\n",
    "    date=filename.split(\"last_24_\",1)[1]\n",
    "    date_format_str = '%m-%d_%H%M'            \n",
    "    start = datetime.strptime(date.split(\".png\",1)[0], date_format_str)\n",
    "    end = start + timedelta(1) #relativedelta(day=1)\n",
    "    return start.strftime('2022-%m-%dT%H:%M:00.000Z'), end.strftime('2022-%m-%dT%H:%M:00.000Z')\n",
    "    \n",
    "#while True:\n",
    "#    try:\n",
    "def count_missing_data(start_ts, elastic_start_ts):\n",
    "    date_format_str = '%Y-%m-%dT%H:%M:%S.%fZ'\n",
    "    start = datetime.strptime(start_ts, date_format_str)\n",
    "    end =  datetime.strptime(elastic_start_ts, date_format_str)\n",
    "    diff_in_minutes = (end-start).total_seconds() / 60\n",
    "    return diff_in_minutes / 15\n",
    "\n",
    "basepath=os.path.join( \"C:\\\\\", \"Projects\", \"aurora\",\"maggraphs\",\"test\")\n",
    "\n",
    "#filename=\n",
    "#filename=\n",
    "#filename=\n",
    "#filename=\n",
    "# [\"preliminary_k_index_last_24_11_21_0730.png\"]  - two peaks of q=5\n",
    "#for filename in os.listdir(basepath):\n",
    "files=[      \n",
    "      \"preliminary_k_index_last_24_11-08_0645.png\",\n",
    "      \"preliminary_k_index_last_24_11-14_0730.png\",\n",
    "      \"preliminary_k_index_last_24_11-15_0800.png\",\n",
    "      \"preliminary_k_index_last_24_11-20_1030.png\",\n",
    "      \"preliminary_k_index_last_24_11-21_0730.png\",\n",
    "      \"preliminary_k_index_last_24_12-03_1530.png\",\n",
    "      \"preliminary_k_index_last_24_12-05_0900.png\",\n",
    "      \"preliminary_k_index_last_24_12-10_2015.png\",\n",
    "      \"preliminary_k_index_last_24_01-08_1745.png\",\n",
    "        \"preliminary_k_index_last_24_01-09_2115.png\",  # but cut off data around 00:00\n",
    "        \"preliminary_k_index_last_24_01-10_0730.png\",  #problem with several zeros\n",
    "    \"preliminary_k_index_last_24_01-01_1815.png\"\n",
    "        ] \n",
    "#test data\n",
    "#files=[\"preliminary_k_index_last_24_12-02_2130.png\"]\n",
    "#files=[\"preliminary_k_index_last_24_11-21_2230.png\"]\n",
    "#files=[\"preliminary_k_index_last_24_12-20_0800.png\"]\n",
    "#files=[\"preliminary_k_index_last_24_12-31_1530.png\"]\n",
    "files=[\"preliminary_k_index_last_24_01-08_1745.png\"]\n",
    "\n",
    "#train_data.append([])\n",
    "for filename in files:\n",
    "#for filename in [\"preliminary_k_index_last_24_12-02_2130.png\"]:\n",
    "    train_q=[]\n",
    "    predict_q=[]\n",
    "    if os.path.isfile(os.path.join(basepath, filename)):\n",
    "        print(filename)\n",
    " \n",
    "    start_ts,end_ts=get_image_data_range(filename, 0)\n",
    "    elastic_data = client.mean_comp(\"mag-logback\", start_ts, end_ts)\n",
    "    need_append = count_missing_data(start_ts, elastic_data[0]['ts'])\n",
    "    \n",
    "    if need_append>0:\n",
    "        print('missing records: ' + str(need_append))\n",
    "        new_array = []\n",
    "        num=int(need_append)\n",
    "        for i in range(0,num):\n",
    "            new_array.append({'min_x':elastic_data[0]['min_x'],'min_y':elastic_data[0]['min_y']})\n",
    "        new_array.extend(elastic_data)\n",
    "        elastic_data = new_array\n",
    "    train_q, predict_q = analising(os.path.join(basepath, filename), elastic_data)    \n",
    "    print(\"elastic size:\" + str(len(elastic_data)) +\" need append: \"+ str(need_append))\n",
    "      \n",
    "a = numpy.asarray(train_data)\n",
    "numpy.savetxt(\"test_data.csv\",  a, fmt=\"%s\",  delimiter=\",\", header=\"xAmp_30,yAmp_30,xAmp_15,yAmp_15,xQ_30,xQ_15,yQ_15,kiruna_Q\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7368421052631579\n",
      "8 predicted:4 kiruna:3\n",
      "10 predicted:4 kiruna:3\n",
      "12 predicted:1 kiruna:2\n",
      "13 predicted:1 kiruna:0\n",
      "16 predicted:1 kiruna:0\n",
      "18 predicted:0 kiruna:1\n",
      "19 predicted:0 kiruna:1\n",
      "36 predicted:0 kiruna:1\n",
      "39 predicted:1 kiruna:0\n",
      "46 predicted:0 kiruna:1\n",
      "53 predicted:0 kiruna:1\n",
      "58 predicted:1 kiruna:0\n",
      "62 predicted:1 kiruna:0\n",
      "72 predicted:1 kiruna:0\n",
      "78 predicted:3 kiruna:2\n",
      "86 predicted:2 kiruna:1\n",
      "93 predicted:1 kiruna:2\n",
      "0.17894736842105263\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def encode_labels(df):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == type(object):\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "    return df\n",
    "\n",
    "\n",
    "training_df = pd.read_csv('../maggraphs/files/train_data.csv')\n",
    "test_df = pd.read_csv('../maggraphs/files/test_data.csv')\n",
    "#test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "approved = training_df[\"kiruna_Q\"]\n",
    "training_df = training_df.drop('kiruna_Q', axis=1)\n",
    "\n",
    "q_kiruna = test_df[\"kiruna_Q\"]\n",
    "test_df = test_df.drop('kiruna_Q', axis=1)\n",
    "\n",
    "training_df = encode_labels(training_df)\n",
    "test_df = encode_labels(test_df)\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier().fit(training_df, approved)\n",
    "y_pred = model.predict(test_df)\n",
    "print(\"accuracy: \",accuracy_score(q_kiruna, y_pred))\n",
    "\n",
    "res = model.predict_proba(test_df)\n",
    "predicted_df = pd.Series(res[:,1])\n",
    "\n",
    "#predicted_df.to_csv(\"../maggraphs/files/prediction_q_logistic_tree_rgr.csv\", index=False)\n",
    "sum_q=0\n",
    "diff=0\n",
    "for idx, predicted_value in enumerate(y_pred):\n",
    "    #sum_q+=q_kiruna[idx]\n",
    "    sum_q+=1\n",
    "    if (idx+1<len(q_kiruna)) and predicted_value!= q_kiruna[idx] and predicted_value!= q_kiruna[idx+1]:\n",
    "        #diff+=abs(predicted_value-q_kiruna[idx])\n",
    "        diff+=1\n",
    "        print(str(idx) +\" predicted:\" +str(predicted_value) + \" kiruna:\"+str(q_kiruna[idx]))\n",
    "print(diff/sum_q)\n",
    "print(len(y_pred))\n",
    "# prev: 0.2127659574468085\n",
    "# new: 0.14736842105263157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.857566765578635 0.8397626112759644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X1, X2, y1, y2 = train_test_split(training_df, approved, random_state=0,train_size=0.5)\n",
    "y2_model = model.fit(X1, y1).predict(X2)\n",
    "y1_model = model.fit(X2, y2).predict(X1)\n",
    "print(accuracy_score(y1, y1_model), accuracy_score(y2, y2_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DENIS_~1\\AppData\\Local\\Temp/ipykernel_29940/3683197767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstart_point\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_kiruna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_kiruna\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_point\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_q' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "start_point = 0\n",
    "print(len(q_kiruna))\n",
    "print(q_kiruna[start_point:len(train_q)])\n",
    "print(len(predict_q))\n",
    "print(predict_q)\n",
    "print(len(y_pred[start_point:len(predict_q)]))\n",
    "print(y_pred)\n",
    "\n",
    "data = [q_kiruna[start_point:len(predict_q)],\n",
    "predict_q[start_point:len(predict_q)],\n",
    "       y_pred[start_point:len(predict_q)]]\n",
    "X = np.arange(start_point,len(predict_q))\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(15, 3)\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.bar(X + 0.00, data[0], color = 'b', width = 0.3)\n",
    "ax.bar(X + 0.3, data[1], color = 'r', width = 0.3)\n",
    "ax.bar(X + 0.7, data[2], color = 'y', width = 0.3)\n",
    "ax.legend(labels=['k_index_15min', 'calc4', 'predicted'])\n",
    "#ax.bar(X + 0.50, data[2], color = 'r', width = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
